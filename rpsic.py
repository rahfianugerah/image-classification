# -*- coding: utf-8 -*-
"""rpsic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19NZIYGKFZfpejRnAFNo-X2EGfjForXyN

# RPS (*Rock Paper Scissors*) Image Classification
"""

# Print tensorflow version
import tensorflow as tf
print(tf.__version__)

"""## Download Required File"""

# Download the zipped file using wget
!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip

!sudo apt install tree

"""## Extract The Downloaded File and Create Directory for Train Set and Validation Set"""

import zipfile
import os

# Extract file zip
zip_dir = '/content/rockpaperscissors.zip'
zip = zipfile.ZipFile(zip_dir, 'r')
zip.extractall('/content')
zip.close()

# Spliting train set and validation set
base_dir = '/content/rockpaperscissors'
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')

os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

!tree -d /content

"""## Spliting Images Dataset"""

import os
import shutil
from sklearn.model_selection import train_test_split

# Define base directory and class labels
base_dir = "/content/rockpaperscissors"
classes = ["rock", "paper", "scissors"]

# Create train and validation directories (handling existence)
train_dir = os.path.join(base_dir, "train")
val_dir = os.path.join(base_dir, "val")
os.makedirs(train_dir, exist_ok=True)
os.makedirs(val_dir, exist_ok=True)

# Function to split images for each class
def split_class_images(class_dir, test_size=0.4, random_state=42):
  images = os.listdir(class_dir)
  train_images, val_images = train_test_split(images, test_size=test_size, random_state=random_state)

  # Move images to train and validation directories
  for img in train_images:
    src = os.path.join(class_dir, img)
    dst = os.path.join(train_dir, class_name, img)  # Include class name in destination
    os.makedirs(os.path.dirname(dst), exist_ok=True)  # Create subdirectories if needed
    shutil.move(src, dst)  # Use move instead of copy for efficiency

  for img in val_images:
    src = os.path.join(class_dir, img)
    dst = os.path.join(val_dir, class_name, img)
    os.makedirs(os.path.dirname(dst), exist_ok=True)
    shutil.move(src, dst)

# Split images for each class
for class_name in classes:
  class_dir = os.path.join(base_dir, class_name)
  split_class_images(class_dir)

# Print confirmation message
print(f"Dataset Splitting Completed!\nTrain Folder: {os.listdir(train_dir)}\nValidation Folder: {os.listdir(val_dir)}")

"""## Create Callback"""

# Create Callback
class Callback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.98 and logs.get('val_accuracy') > 0.98):
      print("Accuracy have been achieved!")
      self.model.stop_training = True
callbacks= Callback()

"""## Create Image Classification Model using Tensorflow, Image Data Generator, CNN and Adam Optimizer"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define data augmentation parameters
data_augmentations = dict(
    rescale=1./255,
    rotation_range=40,
    horizontal_flip=True,
    shear_range=0.2,
    fill_mode='nearest'
)

# Create separate ImageDataGenerator instances for training and validation
train_datagen = ImageDataGenerator(**data_augmentations)
validation_datagen = ImageDataGenerator(rescale=1./255)

# Use a function to define the image classification model for reusability
def create_image_classification_model(input_shape=(100, 100, 3), num_classes=3):
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(16, (5, 5), activation='relu', input_shape=input_shape),
      tf.keras.layers.MaxPooling2D(2, 2),
      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
      tf.keras.layers.MaxPooling2D(2, 2),
      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
      tf.keras.layers.MaxPooling2D(2,2),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation='relu'),
      tf.keras.layers.Dense(num_classes, activation='softmax')  # Output layer with num_classes
  ])
  return model

# Create the model
model = create_image_classification_model(input_shape=(100, 100, 3), num_classes=3)

model.summary()

model.compile(optimizer=tf.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Generate data using flow_from_directory
train_generator = train_datagen.flow_from_directory(train_dir, target_size=(100, 100), batch_size=16, class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(val_dir, target_size=(100, 100), batch_size=16, class_mode='categorical')

# Calculate steps per epoch for training and validation generators efficiently
history = model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=25,
                    validation_data=validation_generator, validation_steps=len(validation_generator),
                    verbose=2, callbacks=[callbacks])

"""## Model Evaluation"""

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

# Create a subplot figure
plt.figure(figsize=(20, 5))  # Adjust figure size as needed

# Subplot for Accuracy
plt.subplot(1, 2, 1)  # 1 row, 2 columns, subplot 1
plt.plot(epochs, acc, 'r', label='Train Accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')
plt.title('Model Accuracy')
plt.legend(loc=0)

# Subplot for all
plt.subplot(1, 2, 2)  # 1 row, 2 columns, subplot 2
plt.plot(epochs, acc, 'blue', label='Train Accuracy')
plt.plot(epochs, val_acc, 'green', label='Validation Accuracy')
plt.plot(epochs, loss, 'red', label='Train Loss')
plt.plot(epochs, val_loss, 'orange', label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.legend(loc=0)


# Adjust layout to prevent overlapping elements
plt.tight_layout()

plt.show()

"""## Predicting Image"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
# %matplotlib inline

def predict_image(model, image_path):
  # Load and resize the image
  img = image.load_img(image_path, target_size=(100, 100))

  # Display the image
  plt.imshow(img)
  plt.show()

  # Preprocess the image
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  x /= 255.0  # Normalize pixel values

  # Predict the class
  classes = model.predict(x, batch_size=10)
  predict_class_index = np.argmax(classes)

  # Load class labels (assuming they're stored in a list)
  class_labels = ['paper', 'rock', 'scissors']

  predict = class_labels[predict_class_index]

  # Print results
  print(f"Filename: {image_path}")
  print(f"Predicted Class: {predict}")

# Upload the image
uploaded = files.upload()

# Process the uploaded image
if uploaded:
  image_path = list(uploaded.keys())[0]  # Get the first uploaded file path
  predict_image(model, image_path)

"""## Deploy the model"""

import tensorflow as tf
import pathlib

export_dir = 'model/'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('rpsmodel.tflite')
tflite_model_file.write_bytes(tflite_model)